{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from arbiter_puf import ArbiterPuf\n",
    "from xor_puf import XorPuf\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  drops responses in Y  adds responses in X\n",
    "def modify_data_to_train(data):\n",
    "    training_data = []\n",
    "    test_data = []\n",
    "    for i in data:\n",
    "        test_data.append(i.pop())\n",
    "        training_data.append(i)\n",
    "    return np.asarray(training_data), np.asarray(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Arbiter PUF ========================\n",
      "Number of Stages:  32\n",
      "Cross Validation Mean Score:  50.1%\n",
      "Accuracy :  0.50215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.48      0.49     10048\n",
      "           1       0.50      0.52      0.51      9952\n",
      "\n",
      "    accuracy                           0.50     20000\n",
      "   macro avg       0.50      0.50      0.50     20000\n",
      "weighted avg       0.50      0.50      0.50     20000\n",
      "\n",
      "=======================================================\n",
      "Number of Stages:  64\n",
      "Cross Validation Mean Score:  56.39999999999999%\n",
      "Accuracy :  0.56905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.57      0.57     10113\n",
      "           1       0.56      0.57      0.57      9887\n",
      "\n",
      "    accuracy                           0.57     20000\n",
      "   macro avg       0.57      0.57      0.57     20000\n",
      "weighted avg       0.57      0.57      0.57     20000\n",
      "\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "list_of_number_of_bits = [32, 64]\n",
    "data_size = 100000\n",
    "print('================== Arbiter PUF ========================')\n",
    "for bit in list_of_number_of_bits:\n",
    "    print('Number of Stages: ', bit)\n",
    "    dataset = ArbiterPuf(bit).calculate_responses(data_size)\n",
    "    X,Y = modify_data_to_train(dataset)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    LGR_Classifier = LogisticRegression()\n",
    "    LGR_Classifier.fit(X_train, Y_train)\n",
    "    scores = cross_val_score(LGR_Classifier, X_train, Y_train, cv=10, scoring=\"accuracy\")\n",
    "    y_pred = LGR_Classifier.predict(X_test)\n",
    "    print (\"Cross Validation Mean Score: \", '{}%'.format(np.round(scores.mean(), 3) * 100))  \n",
    "    print(\"Accuracy : \", accuracy_score(Y_test, y_pred))\n",
    "    print(classification_report(Y_test, y_pred))\n",
    "    print('=======================================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(data): # adding phi to the dataset when training\n",
    "    training_data = []\n",
    "    test_data = []\n",
    "    for i in data:\n",
    "        test_data.append(i.pop())\n",
    "        phi = [ArbiterPuf.calculate_phi(i[j:]) for j in range(len(i))]\n",
    "        training_data.append(phi)   \n",
    "    return np.asarray(training_data), np.asarray(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Arbiter PUF with Phi ========================\n",
      "Number of Stages:  32\n",
      "Cross Validation Mean Score:  99.9%\n",
      "Accuracy :  0.9985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     10037\n",
      "           1       1.00      1.00      1.00      9963\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       1.00      1.00      1.00     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "=======================================================\n",
      "Number of Stages:  64\n",
      "Cross Validation Mean Score:  99.9%\n",
      "Accuracy :  0.99775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     10061\n",
      "           1       1.00      1.00      1.00      9939\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       1.00      1.00      1.00     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "list_of_number_of_bits = [32, 64]\n",
    "data_size = 100000\n",
    "print('================== Arbiter PUF with Phi ========================')\n",
    "for bit in list_of_number_of_bits:\n",
    "    print('Number of Stages: ', bit)\n",
    "    dataset = ArbiterPuf(bit).calculate_responses(data_size)\n",
    "    X,Y = modify_data(dataset)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    LGR_Classifier = LogisticRegression()\n",
    "    LGR_Classifier.fit(X_train, Y_train)\n",
    "    scores = cross_val_score(LGR_Classifier, X_train, Y_train, cv=10, scoring=\"accuracy\")\n",
    "    y_pred = LGR_Classifier.predict(X_test)\n",
    "    print (\"Cross Validation Mean Score: \", '{}%'.format(np.round(scores.mean(), 3) * 100))  \n",
    "    print(\"Accuracy : \", accuracy_score(Y_test, y_pred))\n",
    "    print(classification_report(Y_test, y_pred))\n",
    "    print('=======================================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Xor PUF 3 Pufs ========================\n",
      "Number of Stages:  5\n",
      "Cross Validation Mean Score:  85.2%\n",
      "Accuracy :  0.87265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      9999\n",
      "           1       0.87      0.87      0.87     10001\n",
      "\n",
      "    accuracy                           0.87     20000\n",
      "   macro avg       0.87      0.87      0.87     20000\n",
      "weighted avg       0.87      0.87      0.87     20000\n",
      "\n",
      "=======================================================\n",
      "Number of Stages:  10\n",
      "Cross Validation Mean Score:  63.0%\n",
      "Accuracy :  0.6303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64      9978\n",
      "           1       0.64      0.61      0.62     10022\n",
      "\n",
      "    accuracy                           0.63     20000\n",
      "   macro avg       0.63      0.63      0.63     20000\n",
      "weighted avg       0.63      0.63      0.63     20000\n",
      "\n",
      "=======================================================\n",
      "Number of Stages:  15\n"
     ]
    }
   ],
   "source": [
    "list_of_number_of_bits = [5, 10, 15, 20, 32]\n",
    "data_size = 100000\n",
    "number_of_pufs = [3, 4, 5]\n",
    "for j in number_of_pufs:\n",
    "    print(f\"================== Xor PUF {j} Pufs ========================\")\n",
    "    for bit in list_of_number_of_bits:\n",
    "        print('Number of Stages: ', bit)\n",
    "        # dataset = ArbiterPuf(bit).calculate_responses(data_size)\n",
    "        dataset = XorPuf(bit, j).calculate_responses(data_size)\n",
    "        X,Y = modify_data(dataset)\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "        LGR_Classifier = LogisticRegression()\n",
    "        LGR_Classifier.fit(X_train, Y_train)\n",
    "        scores = cross_val_score(LGR_Classifier, X_train, Y_train, cv=10, scoring=\"accuracy\")\n",
    "        y_pred = LGR_Classifier.predict(X_test)\n",
    "        print (\"Cross Validation Mean Score: \", '{}%'.format(np.round(scores.mean(), 3) * 100))  \n",
    "        print(\"Accuracy : \", accuracy_score(Y_test, y_pred))\n",
    "        print(classification_report(Y_test, y_pred))\n",
    "        print('=======================================================')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
