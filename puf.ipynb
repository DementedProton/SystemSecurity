{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from arbiter_puf import ArbiterPuf\n",
    "from xor_puf import XorPuf\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  drops responses in Y  adds responses in X\n",
    "def modify_data_to_train(data):\n",
    "    training_data = []\n",
    "    test_data = []\n",
    "    for i in data:\n",
    "        test_data.append(i.pop())\n",
    "        training_data.append(i)\n",
    "    return np.asarray(training_data), np.asarray(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Arbiter PUF ========================\n",
      "Number of Stages:  32\n",
      "Cross Validation Mean Score:  50.1%\n",
      "Accuracy :  0.50215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.48      0.49     10048\n",
      "           1       0.50      0.52      0.51      9952\n",
      "\n",
      "    accuracy                           0.50     20000\n",
      "   macro avg       0.50      0.50      0.50     20000\n",
      "weighted avg       0.50      0.50      0.50     20000\n",
      "\n",
      "=======================================================\n",
      "Number of Stages:  64\n",
      "Cross Validation Mean Score:  56.39999999999999%\n",
      "Accuracy :  0.56905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.57      0.57     10113\n",
      "           1       0.56      0.57      0.57      9887\n",
      "\n",
      "    accuracy                           0.57     20000\n",
      "   macro avg       0.57      0.57      0.57     20000\n",
      "weighted avg       0.57      0.57      0.57     20000\n",
      "\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "list_of_number_of_bits = [32, 64]\n",
    "data_size = 100000\n",
    "print('================== Arbiter PUF ========================')\n",
    "for bit in list_of_number_of_bits:\n",
    "    print('Number of Stages: ', bit)\n",
    "    dataset = ArbiterPuf(bit).calculate_responses(data_size)\n",
    "    X,Y = modify_data_to_train(dataset)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    LGR_Classifier = LogisticRegression()\n",
    "    LGR_Classifier.fit(X_train, Y_train)\n",
    "    scores = cross_val_score(LGR_Classifier, X_train, Y_train, cv=10, scoring=\"accuracy\")\n",
    "    y_pred = LGR_Classifier.predict(X_test)\n",
    "    print (\"Cross Validation Mean Score: \", '{}%'.format(np.round(scores.mean(), 3) * 100))  \n",
    "    print(\"Accuracy : \", accuracy_score(Y_test, y_pred))\n",
    "    print(classification_report(Y_test, y_pred))\n",
    "    print('=======================================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(data): # adding phi to the dataset when training\n",
    "    training_data = []\n",
    "    test_data = []\n",
    "    for i in data:\n",
    "        test_data.append(i.pop())\n",
    "        phi = [ArbiterPuf.calculate_phi(i[j:]) for j in range(len(i))]\n",
    "        training_data.append(phi)   \n",
    "    return np.asarray(training_data), np.asarray(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Arbiter PUF with Phi ========================\n",
      "Number of Stages:  32\n",
      "Cross Validation Mean Score:  99.9%\n",
      "Accuracy :  0.9985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     10037\n",
      "           1       1.00      1.00      1.00      9963\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       1.00      1.00      1.00     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "=======================================================\n",
      "Number of Stages:  64\n",
      "Cross Validation Mean Score:  99.9%\n",
      "Accuracy :  0.99775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     10061\n",
      "           1       1.00      1.00      1.00      9939\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       1.00      1.00      1.00     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "list_of_number_of_bits = [32, 64]\n",
    "data_size = 100000\n",
    "print('================== Arbiter PUF with Phi ========================')\n",
    "for bit in list_of_number_of_bits:\n",
    "    print('Number of Stages: ', bit)\n",
    "    dataset = ArbiterPuf(bit).calculate_responses(data_size)\n",
    "    X,Y = modify_data(dataset)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    LGR_Classifier = LogisticRegression()\n",
    "    LGR_Classifier.fit(X_train, Y_train)\n",
    "    scores = cross_val_score(LGR_Classifier, X_train, Y_train, cv=10, scoring=\"accuracy\")\n",
    "    y_pred = LGR_Classifier.predict(X_test)\n",
    "    print (\"Cross Validation Mean Score: \", '{}%'.format(np.round(scores.mean(), 3) * 100))  \n",
    "    print(\"Accuracy : \", accuracy_score(Y_test, y_pred))\n",
    "    print(classification_report(Y_test, y_pred))\n",
    "    print('=======================================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Xor PUF 3 Pufs ========================\n",
      "Number of Stages:  5\n",
      "Cross Validation Mean Score:  75.0%\n",
      "Accuracy :  0.7473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75     10072\n",
      "           1       0.75      0.75      0.75      9928\n",
      "\n",
      "    accuracy                           0.75     20000\n",
      "   macro avg       0.75      0.75      0.75     20000\n",
      "weighted avg       0.75      0.75      0.75     20000\n",
      "\n",
      "=======================================================\n",
      "Number of Stages:  10\n",
      "Cross Validation Mean Score:  55.900000000000006%\n",
      "Accuracy :  0.5598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.55      0.56     10011\n",
      "           1       0.56      0.57      0.56      9989\n",
      "\n",
      "    accuracy                           0.56     20000\n",
      "   macro avg       0.56      0.56      0.56     20000\n",
      "weighted avg       0.56      0.56      0.56     20000\n",
      "\n",
      "=======================================================\n",
      "Number of Stages:  15\n",
      "Cross Validation Mean Score:  56.699999999999996%\n",
      "Accuracy :  0.57285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.58      0.58     10000\n",
      "           1       0.57      0.57      0.57     10000\n",
      "\n",
      "    accuracy                           0.57     20000\n",
      "   macro avg       0.57      0.57      0.57     20000\n",
      "weighted avg       0.57      0.57      0.57     20000\n",
      "\n",
      "=======================================================\n",
      "Number of Stages:  20\n",
      "Cross Validation Mean Score:  68.60000000000001%\n",
      "Accuracy :  0.68345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68      9994\n",
      "           1       0.68      0.69      0.68     10006\n",
      "\n",
      "    accuracy                           0.68     20000\n",
      "   macro avg       0.68      0.68      0.68     20000\n",
      "weighted avg       0.68      0.68      0.68     20000\n",
      "\n",
      "=======================================================\n",
      "================== Xor PUF 4 Pufs ========================\n",
      "Number of Stages:  5\n",
      "Cross Validation Mean Score:  69.0%\n",
      "Accuracy :  0.69015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      6197\n",
      "           1       0.69      1.00      0.82     13803\n",
      "\n",
      "    accuracy                           0.69     20000\n",
      "   macro avg       0.35      0.50      0.41     20000\n",
      "weighted avg       0.48      0.69      0.56     20000\n",
      "\n",
      "=======================================================\n",
      "Number of Stages:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/v/PycharmProjects/puf/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Mean Score:  51.7%\n",
      "Accuracy :  0.52205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      9545\n",
      "           1       0.52      1.00      0.69     10455\n",
      "\n",
      "    accuracy                           0.52     20000\n",
      "   macro avg       0.26      0.50      0.34     20000\n",
      "weighted avg       0.27      0.52      0.36     20000\n",
      "\n",
      "=======================================================\n",
      "Number of Stages:  15\n",
      "Cross Validation Mean Score:  50.0%\n",
      "Accuracy :  0.5045\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.93      0.66     10269\n",
      "           1       0.43      0.06      0.10      9731\n",
      "\n",
      "    accuracy                           0.50     20000\n",
      "   macro avg       0.47      0.49      0.38     20000\n",
      "weighted avg       0.47      0.50      0.39     20000\n",
      "\n",
      "=======================================================\n",
      "Number of Stages:  20\n",
      "Cross Validation Mean Score:  52.900000000000006%\n",
      "Accuracy :  0.52765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.69     10553\n",
      "           1       0.00      0.00      0.00      9447\n",
      "\n",
      "    accuracy                           0.53     20000\n",
      "   macro avg       0.26      0.50      0.35     20000\n",
      "weighted avg       0.28      0.53      0.36     20000\n",
      "\n",
      "=======================================================\n",
      "================== Xor PUF 5 Pufs ========================\n",
      "Number of Stages:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/v/PycharmProjects/puf/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Mean Score:  62.9%\n",
      "Accuracy :  0.62285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.62     10119\n",
      "           1       0.62      0.63      0.62      9881\n",
      "\n",
      "    accuracy                           0.62     20000\n",
      "   macro avg       0.62      0.62      0.62     20000\n",
      "weighted avg       0.62      0.62      0.62     20000\n",
      "\n",
      "=======================================================\n",
      "Number of Stages:  10\n",
      "Cross Validation Mean Score:  58.9%\n",
      "Accuracy :  0.59115\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.60      0.60     10096\n",
      "           1       0.59      0.58      0.58      9904\n",
      "\n",
      "    accuracy                           0.59     20000\n",
      "   macro avg       0.59      0.59      0.59     20000\n",
      "weighted avg       0.59      0.59      0.59     20000\n",
      "\n",
      "=======================================================\n",
      "Number of Stages:  15\n",
      "Cross Validation Mean Score:  54.7%\n",
      "Accuracy :  0.54515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.54      0.54      9992\n",
      "           1       0.55      0.55      0.55     10008\n",
      "\n",
      "    accuracy                           0.55     20000\n",
      "   macro avg       0.55      0.55      0.55     20000\n",
      "weighted avg       0.55      0.55      0.55     20000\n",
      "\n",
      "=======================================================\n",
      "Number of Stages:  20\n",
      "Cross Validation Mean Score:  51.4%\n",
      "Accuracy :  0.5112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.47      0.49     10021\n",
      "           1       0.51      0.55      0.53      9979\n",
      "\n",
      "    accuracy                           0.51     20000\n",
      "   macro avg       0.51      0.51      0.51     20000\n",
      "weighted avg       0.51      0.51      0.51     20000\n",
      "\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "list_of_number_of_bits = [5, 10, 15, 20]\n",
    "data_size = 100000\n",
    "number_of_pufs = [3, 4, 5]\n",
    "for j in number_of_pufs:\n",
    "    print(f\"================== Xor PUF {j} Pufs ========================\")\n",
    "    for bit in list_of_number_of_bits:\n",
    "        print('Number of Stages: ', bit)\n",
    "        # dataset = ArbiterPuf(bit).calculate_responses(data_size)\n",
    "        dataset = XorPuf(bit, j).calculate_responses(data_size)\n",
    "        X,Y = modify_data(dataset)\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "        LGR_Classifier = LogisticRegression()\n",
    "        LGR_Classifier.fit(X_train, Y_train)\n",
    "        scores = cross_val_score(LGR_Classifier, X_train, Y_train, cv=10, scoring=\"accuracy\")\n",
    "        y_pred = LGR_Classifier.predict(X_test)\n",
    "        print (\"Cross Validation Mean Score: \", '{}%'.format(np.round(scores.mean(), 3) * 100))  \n",
    "        print(\"Accuracy : \", accuracy_score(Y_test, y_pred))\n",
    "        print(classification_report(Y_test, y_pred))\n",
    "        print('=======================================================')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
